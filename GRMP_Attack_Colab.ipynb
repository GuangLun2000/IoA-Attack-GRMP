{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GRMP Attack Experiment - Google Colab\n",
        "\n",
        "This notebook runs the Graph Representation-based Model Poisoning (GRMP) attack experiment on AG News dataset.\n",
        "\n",
        "**Paper**: Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "2. **Upload Files**: Upload all Python files (main.py, client.py, server.py, data_loader.py, models.py, visualization.py) to Colab\n",
        "3. **Run all cells**: Runtime ‚Üí Run all\n",
        "4. **View results**: Check the `results/` folder for outputs and visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install torch>=2.0.0 transformers>=4.35.0 datasets>=2.0.0 numpy>=1.21.0 scikit-learn>=1.0.0 pandas>=1.3.0 tqdm>=4.62.0 matplotlib>=3.4.0 seaborn>=0.11.0 --quiet\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Verify Files and GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if files exist\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "required_files = ['main.py', 'client.py', 'server.py', 'data_loader.py', 'models.py', 'visualization.py']\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"‚ö†Ô∏è  Missing files: {missing_files}\")\n",
        "    print(\"Please upload these files to Colab using the file uploader.\")\n",
        "else:\n",
        "    print(\"‚úÖ All required files found!\")\n",
        "    for f in required_files:\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower.\")\n",
        "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Experiment\n",
        "\n",
        "Choose one of the configurations below:\n",
        "- **Quick Test**: Faster execution (~10-15 min), reduced rounds and dataset\n",
        "- **Full Experiment**: Complete experiment (~1-2 hours), full dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment Configuration\n",
        "# Modify these parameters as needed\n",
        "\n",
        "EXPERIMENT_CONFIG = {\n",
        "    # ========== Experiment Configuration ==========\n",
        "    'experiment_name': 'colab_grmp_attack',  # Name for result files\n",
        "    'seed': 42,  # Random seed for reproducibility\n",
        "    \n",
        "    # ========== Federated Learning Setup ==========\n",
        "    'num_clients': 6,  # Total number of federated learning clients\n",
        "    'num_attackers': 2,  # Number of attacker clients\n",
        "    'num_rounds': 20,  # Total number of federated learning rounds (reduce to 5 for quick test)\n",
        "    \n",
        "    # ========== Training Hyperparameters ==========\n",
        "    'client_lr': 2e-5,  # Learning rate for local client training\n",
        "    'server_lr': 0.8,  # Server learning rate for model aggregation\n",
        "    'batch_size': 16,  # Batch size for local training\n",
        "    'local_epochs': 5,  # Number of local training epochs per round\n",
        "    'alpha': 0.01,  # Proximal regularization coefficient\n",
        "    \n",
        "    # ========== Data Distribution ==========\n",
        "    'dirichlet_alpha': 0.5,  # Non-IID distribution parameter\n",
        "    'test_sample_rate': 1.0,  # Rate of Business samples to test\n",
        "    'dataset_size_limit': None,  # None = full dataset, or set to int (e.g., 10000) for faster test\n",
        "    \n",
        "    # ========== Attack Configuration ==========\n",
        "    'poison_rate': 1.0,  # Base poisoning rate for attack phase\n",
        "    'attack_start_round': 10,  # Round when attack phase starts\n",
        "    \n",
        "    # ========== Formula 4 Constraint Parameters ==========\n",
        "    'd_T': 0.5,  # Distance threshold for constraint (4b)\n",
        "    'gamma': 10.0,  # Upper bound for constraint (4c)\n",
        "    \n",
        "    # ========== VGAE Training Parameters ==========\n",
        "    'dim_reduction_size': 10000,  # Dimensionality for feature reduction (adjust based on GPU memory)\n",
        "    'vgae_epochs': 20,  # Number of epochs for VGAE training\n",
        "    'vgae_lr': 0.01,  # Learning rate for VGAE optimizer\n",
        "    'vgae_lambda': 0.5,  # Weight for preservation loss\n",
        "    \n",
        "    # ========== Camouflage Optimization Parameters ==========\n",
        "    'camouflage_steps': 30,  # Number of optimization steps for camouflage\n",
        "    'camouflage_lr': 0.1,  # Learning rate for camouflage optimization\n",
        "    'lambda_proximity': 1.0,  # Weight for constraint (4b) proximity loss\n",
        "    'lambda_aggregation': 0.5,  # Weight for constraint (4c) aggregation loss\n",
        "    \n",
        "    # ========== Graph Construction Parameters ==========\n",
        "    'graph_threshold': 0.5,  # Threshold for graph adjacency matrix binarization\n",
        "    \n",
        "    # ========== Defense Mechanism Parameters ==========\n",
        "    'defense_threshold': 0.10,  # Base threshold for defense mechanism\n",
        "    'similarity_alpha': 0.7,  # Weight for pairwise similarities\n",
        "    \n",
        "    # ========== Visualization ==========\n",
        "    'generate_plots': True,  # Whether to generate visualization plots\n",
        "    'run_both_experiments': False,  # Set to True to run baseline + attack (for Figure 5)\n",
        "    'run_attack_only': False,  # Set to True to only run attack experiment\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"\\nExperiment: {EXPERIMENT_CONFIG['experiment_name']}\")\n",
        "print(f\"Rounds: {EXPERIMENT_CONFIG['num_rounds']}\")\n",
        "print(f\"Dataset limit: {EXPERIMENT_CONFIG['dataset_size_limit'] or 'Full dataset'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick Test Configuration (uncomment to use)\n",
        "# QUICK_TEST_CONFIG = {\n",
        "#     'experiment_name': 'colab_quick_test',\n",
        "#     'seed': 42,\n",
        "#     'num_clients': 6,\n",
        "#     'num_attackers': 2,\n",
        "#     'num_rounds': 5,  # Reduced rounds\n",
        "#     'client_lr': 2e-5,\n",
        "#     'server_lr': 0.8,\n",
        "#     'batch_size': 16,\n",
        "#     'local_epochs': 5,\n",
        "#     'alpha': 0.01,\n",
        "#     'dirichlet_alpha': 0.5,\n",
        "#     'test_sample_rate': 1.0,\n",
        "#     'dataset_size_limit': 10000,  # Limited dataset\n",
        "#     'poison_rate': 1.0,\n",
        "#     'attack_start_round': 3,\n",
        "#     'd_T': 0.5,\n",
        "#     'gamma': 10.0,\n",
        "#     'dim_reduction_size': 5000,\n",
        "#     'vgae_epochs': 10,\n",
        "#     'vgae_lr': 0.01,\n",
        "#     'vgae_lambda': 0.5,\n",
        "#     'camouflage_steps': 20,\n",
        "#     'camouflage_lr': 0.1,\n",
        "#     'lambda_proximity': 1.0,\n",
        "#     'lambda_aggregation': 0.5,\n",
        "#     'graph_threshold': 0.5,\n",
        "#     'defense_threshold': 0.10,\n",
        "#     'similarity_alpha': 0.7,\n",
        "#     'generate_plots': True,\n",
        "#     'run_both_experiments': False,\n",
        "#     'run_attack_only': False,\n",
        "# }\n",
        "\n",
        "# To use quick test: EXPERIMENT_CONFIG = QUICK_TEST_CONFIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and run the experiment\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import modules\n",
        "from main import run_experiment, analyze_results\n",
        "\n",
        "# Run experiment\n",
        "print(\"üöÄ Starting GRMP Attack Experiment...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    results, metrics = run_experiment(EXPERIMENT_CONFIG)\n",
        "    \n",
        "    # Analyze results\n",
        "    analyze_results(metrics)\n",
        "    \n",
        "    print(\"\\n‚úÖ Experiment completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Experiment failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: View Results and Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display visualization plots\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "experiment_name = EXPERIMENT_CONFIG['experiment_name']\n",
        "\n",
        "# List of figures to display\n",
        "figures = [\n",
        "    (\"Figure 3: Global Accuracy and ASR\", f\"{experiment_name}_figure3.png\"),\n",
        "    (\"Figure 4: Cosine Similarity\", f\"{experiment_name}_figure4.png\"),\n",
        "    (\"Figure 5: Local Accuracy (No Attack)\", f\"{experiment_name}_figure5.png\"),\n",
        "    (\"Figure 6: Local Accuracy (With Attack)\", f\"{experiment_name}_figure6.png\"),\n",
        "]\n",
        "\n",
        "print(\"üìä Displaying Visualization Figures:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fig_title, fig_name in figures:\n",
        "    fig_path = results_dir / fig_name\n",
        "    if fig_path.exists():\n",
        "        print(f\"\\n‚úÖ {fig_title}\")\n",
        "        display(Image(str(fig_path)))\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  {fig_title} not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display experiment results summary\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "experiment_name = EXPERIMENT_CONFIG['experiment_name']\n",
        "results_path = results_dir / f\"{experiment_name}_results.json\"\n",
        "\n",
        "if results_path.exists():\n",
        "    with open(results_path, 'r') as f:\n",
        "        results_data = json.load(f)\n",
        "    \n",
        "    print(\"üìä Experiment Results Summary:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Display key metrics\n",
        "    rounds = results_data['progressive_metrics']['rounds']\n",
        "    clean_acc = results_data['progressive_metrics']['clean_acc']\n",
        "    attack_asr = results_data['progressive_metrics']['attack_asr']\n",
        "    \n",
        "    print(f\"\\nTotal Rounds: {len(rounds)}\")\n",
        "    print(f\"Final Clean Accuracy: {clean_acc[-1]:.4f}\")\n",
        "    print(f\"Final Attack Success Rate (ASR): {attack_asr[-1]:.4f}\")\n",
        "    print(f\"Peak ASR: {max(attack_asr):.4f}\")\n",
        "    \n",
        "    # Display per-round summary\n",
        "    print(\"\\nüìà Per-Round Summary:\")\n",
        "    print(\"Round | Clean Acc | ASR\")\n",
        "    print(\"-\" * 30)\n",
        "    for i, (r, acc, asr) in enumerate(zip(rounds, clean_acc, attack_asr)):\n",
        "        if i % 5 == 0 or i == len(rounds) - 1:  # Show every 5th round and last round\n",
        "            print(f\"{r:5d} | {acc:9.4f} | {asr:.4f}\")\n",
        "    \n",
        "    # Display local accuracies if available\n",
        "    if 'local_accuracies' in results_data and results_data['local_accuracies']:\n",
        "        print(\"\\nüìä Local Accuracies (Last Round):\")\n",
        "        local_accs = results_data['local_accuracies']\n",
        "        for client_id, accs in sorted(local_accs.items()):\n",
        "            if accs:\n",
        "                print(f\"  Client {client_id}: {accs[-1]:.4f}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Results file not found: {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zip file with all results\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "zip_path = \"grmp_experiment_results.zip\"\n",
        "\n",
        "if results_dir.exists():\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in results_dir.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                zipf.write(file_path, file_path.relative_to(results_dir.parent))\n",
        "    \n",
        "    print(f\"‚úÖ Created zip file: {zip_path}\")\n",
        "    print(f\"\\nüì• Download the file using the cell below\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Results directory not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results zip file\n",
        "from google.colab import files\n",
        "\n",
        "if Path(\"grmp_experiment_results.zip\").exists():\n",
        "    files.download('grmp_experiment_results.zip')\n",
        "    print(\"‚úÖ Download started!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Zip file not found. Run the previous cell first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
