{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GRMP Attack Experiment - Google Colab\n",
        "\n",
        "This notebook runs the Graph Representation-based Model Poisoning (GRMP) attack experiment on AG News dataset.\n",
        "\n",
        "**Paper**: Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "2. **Fetch Code**: Run **Step 0** to clone/download the repo if only this notebook was uploaded.\n",
        "3. **Run all cells**: Runtime ‚Üí Run all\n",
        "4. **View results**: Check the `results/` folder for outputs and visualizations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Fetch Code\n",
        "If you only uploaded this notebook, run this to clone the repository and set the working directory.\n",
        "If you've already uploaded the Python files, it will reuse them without cloning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch repository and set working directory\n",
        "import os, sys, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = 'https://github.com/GuangLun2000/IoA-Attack-GRMP.git'\n",
        "REPO_DIR = Path('IoA-Attack-GRMP')\n",
        "\n",
        "def code_files_present():\n",
        "    return Path('main.py').exists() and Path('client.py').exists()\n",
        "\n",
        "if code_files_present():\n",
        "    print('‚úÖ Code files found in current directory.')\n",
        "else:\n",
        "    if REPO_DIR.exists():\n",
        "        print(f'üîÅ Using existing folder: {REPO_DIR}')\n",
        "    else:\n",
        "        print(f'üì• Cloning {REPO_URL} ...')\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', REPO_URL], check=True)\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"‚úÖ Switched to {Path('.').resolve()}\")\n",
        "\n",
        "# Ensure current path is importable for subsequent cells\n",
        "sys.path.append(str(Path('.').resolve()))\n",
        "print(f\"üìÇ Working directory: {Path('.').resolve()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from pathlib import Path\n",
        "req = Path('requirements.txt')\n",
        "if req.exists():\n",
        "    print('Installing from requirements.txt ...')\n",
        "    %pip install -q -r requirements.txt\n",
        "else:\n",
        "    print('requirements.txt not found; installing explicit package list...')\n",
        "    %pip install -q torch>=2.0.0 transformers>=4.35.0 datasets>=2.0.0 numpy>=1.21.0 scikit-learn>=1.0.0 pandas>=1.3.0 tqdm>=4.62.0 matplotlib>=3.4.0 seaborn>=0.11.0\n",
        "\n",
        "print('‚úÖ Dependencies installed successfully!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Verify Files and GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if files exist\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "required_files = ['main.py', 'client.py', 'server.py', 'data_loader.py', 'models.py', 'visualization.py']\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"‚ö†Ô∏è  Missing files: {missing_files}\")\n",
        "    print(\"Please upload these files to Colab using the file uploader.\")\n",
        "else:\n",
        "    print(\"‚úÖ All required files found!\")\n",
        "    for f in required_files:\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower.\")\n",
        "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Experiment\n",
        "\n",
        "Choose one of the configurations below:\n",
        "- **Quick Test**: Faster execution (~10-15 min), reduced rounds and dataset\n",
        "- **Full Experiment**: Complete experiment (~1-2 hours), full dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment Configuration\n",
        "# Modify these parameters as needed\n",
        "\n",
        "EXPERIMENT_CONFIG = {\n",
        "        # ========== Experiment Configuration ==========\n",
        "        'experiment_name': 'vgae_grmp_attack',  # Name for result files and logs\n",
        "        'seed': 42,  # Random seed for reproducibility (int)\n",
        "        \n",
        "        # ========== Federated Learning Setup ==========\n",
        "        'num_clients': 6,  # Total number of federated learning clients (int)\n",
        "        'num_attackers': 2,  # Number of attacker clients (int, must be < num_clients)\n",
        "        'num_rounds': 30,  # Total number of federated learning rounds (int)\n",
        "        \n",
        "        # ========== Training Hyperparameters ==========\n",
        "        'client_lr': 2e-5,  # Learning rate for local client training (float)\n",
        "        'server_lr': 0.8,  # Server learning rate for model aggregation (float, typically 0.5-1.0)\n",
        "        'batch_size': 128,  # Batch size for local training (int)\n",
        "        'test_batch_size': 128,  # Batch size for test/validation data loaders (int)\n",
        "        # 'local_epochs': 5,  # Number of local training epochs per round (int, per paper Section IV)\n",
        "        'local_epochs': 2,  # Number of local training epochs per round (int, per paper Section IV)\n",
        "        'alpha': 0.01,  # Proximal regularization coefficient Œ± ‚àà [0,1] from paper formula (1) (float)\n",
        "        \n",
        "        # ========== Data Distribution ==========\n",
        "        'dirichlet_alpha': 0.5,  # Dirichlet distribution parameter for non-IID data partitioning (float, lower = more heterogeneous)\n",
        "        'test_sample_rate': 1.0,  # Rate of Business samples to test for ASR evaluation (float, 1.0 = all samples)\n",
        "        # 'dataset_size_limit': None,  # Limit dataset size for faster experimentation (None = use FULL AG News dataset per paper, int = limit training samples)\n",
        "        'dataset_size_limit': 10000,  # Limit dataset size for faster experimentation (None = use FULL AG News dataset per paper, int = limit training samples)\n",
        "\n",
        "        # ========== Attack Configuration ==========\n",
        "        'poison_rate': 1.0,  # Base poisoning rate for attack phase (float, 0.0-1.0)\n",
        "        'attack_start_round': 0,  # Round when attack phase starts (int, learning phase before this round)\n",
        "        \n",
        "        # ========== Formula 4 Constraint Parameters ==========\n",
        "        'd_T': 0.5,  # Distance threshold for constraint (4b): d(w'_j(t), w_g(t)) ‚â§ d_T (float)\n",
        "        'gamma': 10.0,  # Upper bound for constraint (4c): Œ£ Œ≤'_{i,j}(t) d(w_i(t), wÃÑ_i(t)) ‚â§ Œì (float)\n",
        "        \n",
        "        # ========== VGAE Training Parameters ==========\n",
        "        'dim_reduction_size': 10000,  # Dimensionality for feature reduction in VGAE (int, adjust based on GPU memory)\n",
        "        'vgae_epochs': 30,  # Number of epochs for VGAE training per camouflage step (int)\n",
        "        'vgae_lr': 0.01,  # Learning rate for VGAE optimizer (float)\n",
        "        'vgae_lambda': 0.5,  # Weight for preservation loss in camouflage optimization (float, balances attack efficacy vs camouflage)\n",
        "        \n",
        "        # ========== Camouflage Optimization Parameters ==========\n",
        "        'camouflage_steps': 50,  # Number of optimization steps for malicious update camouflage (int)\n",
        "        'camouflage_lr': 0.1,  # Learning rate for camouflage optimization (float)\n",
        "        'lambda_proximity': 2.0,  # Weight for constraint (4b) proximity loss in camouflage (float)\n",
        "        'lambda_aggregation': 0.5,  # Weight for constraint (4c) aggregation loss in camouflage (float)\n",
        "        \n",
        "        # ========== Graph Construction Parameters ==========\n",
        "        'graph_threshold': 0.5,  # Threshold for graph adjacency matrix binarization in VGAE (float, 0.0-1.0)\n",
        "        \n",
        "        # ========== Defense Mechanism Parameters ==========\n",
        "        'defense_threshold': 0.05,  # Base threshold for defense mechanism (float, lower = more strict)\n",
        "        'tolerance_factor': 3.0,  # Tolerance factor for defense mechanism (float, higher = more lenient)\n",
        "        'similarity_alpha': 0.5,  # Weight for pairwise similarities in mixed similarity computation (float, 0.0-1.0)\n",
        "        \n",
        "        # ========== Visualization ==========\n",
        "        'generate_plots': True,  # Whether to generate visualization plots (bool)\n",
        "        'run_both_experiments': False,  # Set to True to run baseline + attack (for Figure 5)\n",
        "        'run_attack_only': False,  # Set to True to only run attack experiment\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"\\nExperiment: {EXPERIMENT_CONFIG['experiment_name']}\")\n",
        "print(f\"Rounds: {EXPERIMENT_CONFIG['num_rounds']}\")\n",
        "print(f\"Dataset limit: {EXPERIMENT_CONFIG['dataset_size_limit'] or 'Full dataset'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick Test Configuration (uncomment to use)\n",
        "# QUICK_TEST_CONFIG = {\n",
        "#     'experiment_name': 'colab_quick_test',\n",
        "#     'seed': 42,\n",
        "#     'num_clients': 6,\n",
        "#     'num_attackers': 2,\n",
        "#     'num_rounds': 5,  # Reduced rounds\n",
        "#     'client_lr': 2e-5,\n",
        "#     'server_lr': 0.8,\n",
        "#     'batch_size': 16,\n",
        "#     'local_epochs': 5,\n",
        "#     'alpha': 0.01,\n",
        "#     'dirichlet_alpha': 0.5,\n",
        "#     'test_sample_rate': 1.0,\n",
        "#     'dataset_size_limit': 10000,  # Limited dataset\n",
        "#     'poison_rate': 1.0,\n",
        "#     'attack_start_round': 3,\n",
        "#     'd_T': 0.5,\n",
        "#     'gamma': 10.0,\n",
        "#     'dim_reduction_size': 5000,\n",
        "#     'vgae_epochs': 10,\n",
        "#     'vgae_lr': 0.01,\n",
        "#     'vgae_lambda': 0.5,\n",
        "#     'camouflage_steps': 20,\n",
        "#     'camouflage_lr': 0.1,\n",
        "#     'lambda_proximity': 1.0,\n",
        "#     'lambda_aggregation': 0.5,\n",
        "#     'graph_threshold': 0.5,\n",
        "#     'defense_threshold': 0.10,\n",
        "#     'similarity_alpha': 0.7,\n",
        "#     'generate_plots': True,\n",
        "#     'run_both_experiments': False,\n",
        "#     'run_attack_only': False,\n",
        "# }\n",
        "\n",
        "# To use quick test: EXPERIMENT_CONFIG = QUICK_TEST_CONFIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and run the experiment\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import modules\n",
        "from main import run_experiment, analyze_results\n",
        "\n",
        "# Run experiment\n",
        "print(\"üöÄ Starting GRMP Attack Experiment...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    results, metrics = run_experiment(EXPERIMENT_CONFIG)\n",
        "    \n",
        "    # Analyze results\n",
        "    analyze_results(metrics)\n",
        "    \n",
        "    print(\"\\n‚úÖ Experiment completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Experiment failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: View Results and Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display visualization plots\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "experiment_name = EXPERIMENT_CONFIG['experiment_name']\n",
        "\n",
        "# List of figures to display\n",
        "figures = [\n",
        "    (\"Figure 3: Global Accuracy and ASR\", f\"{experiment_name}_figure3.png\"),\n",
        "    (\"Figure 4: Cosine Similarity\", f\"{experiment_name}_figure4.png\"),\n",
        "    (\"Figure 5: Local Accuracy (No Attack)\", f\"{experiment_name}_figure5.png\"),\n",
        "    (\"Figure 6: Local Accuracy (With Attack)\", f\"{experiment_name}_figure6.png\"),\n",
        "]\n",
        "\n",
        "print(\"üìä Displaying Visualization Figures:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fig_title, fig_name in figures:\n",
        "    fig_path = results_dir / fig_name\n",
        "    if fig_path.exists():\n",
        "        print(f\"\\n‚úÖ {fig_title}\")\n",
        "        display(Image(str(fig_path)))\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  {fig_title} not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display experiment results summary\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "experiment_name = EXPERIMENT_CONFIG['experiment_name']\n",
        "results_path = results_dir / f\"{experiment_name}_results.json\"\n",
        "\n",
        "if results_path.exists():\n",
        "    with open(results_path, 'r') as f:\n",
        "        results_data = json.load(f)\n",
        "    \n",
        "    print(\"üìä Experiment Results Summary:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Display key metrics\n",
        "    rounds = results_data['progressive_metrics']['rounds']\n",
        "    clean_acc = results_data['progressive_metrics']['clean_acc']\n",
        "    attack_asr = results_data['progressive_metrics']['attack_asr']\n",
        "    \n",
        "    print(f\"\\nTotal Rounds: {len(rounds)}\")\n",
        "    print(f\"Final Clean Accuracy: {clean_acc[-1]:.4f}\")\n",
        "    print(f\"Final Attack Success Rate (ASR): {attack_asr[-1]:.4f}\")\n",
        "    print(f\"Peak ASR: {max(attack_asr):.4f}\")\n",
        "    \n",
        "    # Display per-round summary\n",
        "    print(\"\\nüìà Per-Round Summary:\")\n",
        "    print(\"Round | Clean Acc | ASR\")\n",
        "    print(\"-\" * 30)\n",
        "    for i, (r, acc, asr) in enumerate(zip(rounds, clean_acc, attack_asr)):\n",
        "        if i % 5 == 0 or i == len(rounds) - 1:  # Show every 5th round and last round\n",
        "            print(f\"{r:5d} | {acc:9.4f} | {asr:.4f}\")\n",
        "    \n",
        "    # Display local accuracies if available\n",
        "    if 'local_accuracies' in results_data and results_data['local_accuracies']:\n",
        "        print(\"\\nüìä Local Accuracies (Last Round):\")\n",
        "        local_accs = results_data['local_accuracies']\n",
        "        for client_id, accs in sorted(local_accs.items()):\n",
        "            if accs:\n",
        "                print(f\"  Client {client_id}: {accs[-1]:.4f}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Results file not found: {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zip file with all results\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "zip_path = \"grmp_experiment_results.zip\"\n",
        "\n",
        "if results_dir.exists():\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in results_dir.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                zipf.write(file_path, file_path.relative_to(results_dir.parent))\n",
        "    \n",
        "    print(f\"‚úÖ Created zip file: {zip_path}\")\n",
        "    print(f\"\\nüì• Download the file using the cell below\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Results directory not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results zip file\n",
        "from google.colab import files\n",
        "\n",
        "if Path(\"grmp_experiment_results.zip\").exists():\n",
        "    files.download('grmp_experiment_results.zip')\n",
        "    print(\"‚úÖ Download started!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Zip file not found. Run the previous cell first.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
