{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRMP Attack Experiment - Google Colab\n",
    "\n",
    "This notebook runs the Graph Representation-based Model Poisoning (GRMP) attack experiment on AG News dataset.\n",
    "\n",
    "**Paper**: Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Fetch Code**: Run **Step 0** to clone/download the repo if only this notebook was uploaded.\n",
    "3. **Run all cells**: Runtime ‚Üí Run all\n",
    "4. **View results**: Check the `results/` folder for outputs and visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Fetch Code\n",
    "If you only uploaded this notebook, run this to clone the repository and set the working directory.\n",
    "If you've already uploaded the Python files, it will reuse them without cloning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch repository and set working directory\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = 'https://github.com/GuangLun2000/IoA-Attack-GRMP.git'\n",
    "REPO_DIR = Path('IoA-Attack-GRMP')\n",
    "\n",
    "def code_files_present():\n",
    "    return Path('main.py').exists() and Path('client.py').exists()\n",
    "\n",
    "if code_files_present():\n",
    "    print('‚úÖ Code files found in current directory.')\n",
    "else:\n",
    "    if REPO_DIR.exists():\n",
    "        print(f'üîÅ Using existing folder: {REPO_DIR}')\n",
    "    else:\n",
    "        print(f'üì• Cloning {REPO_URL} ...')\n",
    "        subprocess.run(['git', 'clone', '--depth', '1', REPO_URL], check=True)\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"‚úÖ Switched to {Path('.').resolve()}\")\n",
    "\n",
    "# Ensure current path is importable for subsequent cells\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "print(f\"üìÇ Working directory: {Path('.').resolve()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from pathlib import Path\n",
    "req = Path('requirements.txt')\n",
    "if req.exists():\n",
    "    print('Installing from requirements.txt ...')\n",
    "    %pip install -q -r requirements.txt\n",
    "else:\n",
    "    print('requirements.txt not found; installing explicit package list...')\n",
    "    %pip install -q torch>=2.0.0 transformers>=4.35.0 datasets>=2.0.0 numpy>=1.21.0 scikit-learn>=1.0.0 pandas>=1.3.0 tqdm>=4.62.0 matplotlib>=3.4.0 seaborn>=0.11.0\n",
    "\n",
    "print('‚úÖ Dependencies installed successfully!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify Files and GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if files exist\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "required_files = ['main.py', 'client.py', 'server.py', 'data_loader.py', 'models.py', 'visualization.py']\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ö†Ô∏è  Missing files: {missing_files}\")\n",
    "    print(\"Please upload these files to Colab using the file uploader.\")\n",
    "else:\n",
    "    print(\"‚úÖ All required files found!\")\n",
    "    for f in required_files:\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Experiment\n",
    "\n",
    "**Note**: All experiment parameters are configured in `main.py`. \n",
    "To modify parameters, edit the `config` dictionary in `main.py` before running this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All experiment parameters are configured in main.py\n",
    "# The experiment will use the config dictionary defined in main.py's main() function\n",
    "print(\"‚úÖ Using configuration from main.py\")\n",
    "print(\"   To modify parameters, edit the 'config' dictionary in main.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment using configuration from main.py\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import and run main() function which contains all configuration\n",
    "from main import main\n",
    "\n",
    "print(\"üöÄ Starting GRMP Attack Experiment...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Using configuration from main.py\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # main() function will handle everything: setup, run, and visualization\n",
    "    main()\n",
    "    \n",
    "    print(\"\\n‚úÖ Experiment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Experiment failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View Results and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualization plots\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"results\")\n",
    "# Use default experiment name from main.py (can be changed in main.py config)\n",
    "experiment_name = 'vgae_grmp_attack'\n",
    "\n",
    "# List of figures to display\n",
    "figures = [\n",
    "    (\"Figure 3: Global Accuracy and Stability\", f\"{experiment_name}_figure3.png\"),\n",
    "    (\"Figure 4: Cosine Similarity\", f\"{experiment_name}_figure4.png\"),\n",
    "    (\"Figure 5: Local Accuracy (No Attack)\", f\"{experiment_name}_figure5.png\"),\n",
    "    (\"Figure 6: Local Accuracy (With Attack)\", f\"{experiment_name}_figure6.png\"),\n",
    "]\n",
    "\n",
    "print(\"üìä Displaying Visualization Figures:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fig_title, fig_name in figures:\n",
    "    fig_path = results_dir / fig_name\n",
    "    if fig_path.exists():\n",
    "        print(f\"\\n‚úÖ {fig_title}\")\n",
    "        display(Image(str(fig_path)))\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  {fig_title} not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display experiment results summary\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"results\")\n",
    "# Use default experiment name from main.py (can be changed in main.py config)\n",
    "experiment_name = 'vgae_grmp_attack'\n",
    "results_path = results_dir / f\"{experiment_name}_results.json\"\n",
    "\n",
    "if results_path.exists():\n",
    "    with open(results_path, 'r') as f:\n",
    "        results_data = json.load(f)\n",
    "    \n",
    "    print(\"üìä Experiment Results Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Display key metrics (using actual metrics from progressive_metrics)\n",
    "    progressive = results_data.get('progressive_metrics', {})\n",
    "    rounds = progressive.get('rounds', [])\n",
    "    clean_acc = progressive.get('clean_acc', [])\n",
    "    acc_diff = progressive.get('acc_diff', [])\n",
    "    rejection_rate = progressive.get('rejection_rate', [])\n",
    "    agg_update_norm = progressive.get('agg_update_norm', [])\n",
    "    \n",
    "    if rounds and clean_acc:\n",
    "        print(f\"\\nTotal Rounds: {len(rounds)}\")\n",
    "        print(f\"Initial Clean Accuracy: {clean_acc[0]:.4f}\")\n",
    "        print(f\"Final Clean Accuracy: {clean_acc[-1]:.4f}\")\n",
    "        print(f\"Accuracy Change: {clean_acc[-1] - clean_acc[0]:.4f}\")\n",
    "        \n",
    "        if acc_diff:\n",
    "            print(f\"Final |Œîacc| (Stability): {acc_diff[-1]:.4f}\")\n",
    "            print(f\"Peak |Œîacc|: {max(acc_diff):.4f}\")\n",
    "        \n",
    "        if rejection_rate:\n",
    "            print(f\"Final Rejection Rate: {rejection_rate[-1]:.4f}\")\n",
    "            print(f\"Average Rejection Rate: {sum(rejection_rate) / len(rejection_rate):.4f}\")\n",
    "        \n",
    "        if agg_update_norm:\n",
    "            print(f\"Final Aggregated Update Norm: {agg_update_norm[-1]:.4f}\")\n",
    "        \n",
    "        # Display per-round summary\n",
    "        print(\"\\nüìà Per-Round Summary:\")\n",
    "        print(\"Round | Clean Acc | |Œîacc| | Rejection Rate\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, r in enumerate(rounds):\n",
    "            if i % 5 == 0 or i == len(rounds) - 1:  # Show every 5th round and last round\n",
    "                acc = clean_acc[i] if i < len(clean_acc) else 0.0\n",
    "                diff = acc_diff[i] if i < len(acc_diff) else 0.0\n",
    "                rej = rejection_rate[i] if i < len(rejection_rate) else 0.0\n",
    "                print(f\"{r:5d} | {acc:9.4f} | {diff:6.4f} | {rej:13.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No progressive metrics found in results\")\n",
    "    \n",
    "    # Display local accuracies if available\n",
    "    if 'local_accuracies' in results_data and results_data['local_accuracies']:\n",
    "        print(\"\\nüìä Local Accuracies (Last Round):\")\n",
    "        local_accs = results_data['local_accuracies']\n",
    "        for client_id, accs in sorted(local_accs.items()):\n",
    "            if accs:\n",
    "                print(f\"  Client {client_id}: {accs[-1]:.4f}\")\n",
    "    \n",
    "    # Display configuration summary\n",
    "    if 'config' in results_data:\n",
    "        config = results_data['config']\n",
    "        print(\"\\n‚öôÔ∏è  Experiment Configuration:\")\n",
    "        print(f\"  Clients: {config.get('num_clients', 'N/A')}\")\n",
    "        print(f\"  Attackers: {config.get('num_attackers', 'N/A')}\")\n",
    "        print(f\"  Rounds: {config.get('num_rounds', 'N/A')}\")\n",
    "        print(f\"  Client LR: {config.get('client_lr', 'N/A')}\")\n",
    "        print(f\"  Alpha (FedProx): {config.get('alpha', 'N/A')}\")\n",
    "        print(f\"  d_T: {config.get('d_T', 'N/A')}\")\n",
    "        print(f\"  Gamma: {config.get('gamma', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Results file not found: {results_path}\")\n",
    "    print(\"   Make sure Step 4 has completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file with all results\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"results\")\n",
    "zip_path = \"grmp_experiment_results.zip\"\n",
    "\n",
    "if results_dir.exists():\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in results_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                zipf.write(file_path, file_path.relative_to(results_dir.parent))\n",
    "    \n",
    "    print(f\"‚úÖ Created zip file: {zip_path}\")\n",
    "    print(f\"\\nüì• Download the file using the cell below\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Results directory not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results zip file\n",
    "from google.colab import files\n",
    "\n",
    "if Path(\"grmp_experiment_results.zip\").exists():\n",
    "    files.download('grmp_experiment_results.zip')\n",
    "    print(\"‚úÖ Download started!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Zip file not found. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Exit Running Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ All done. ÊâÄÊúâ‰ªªÂä°ËøêË°åÂÆåÊØï„ÄÇ\")\n",
    "\n",
    "time.sleep(60)\n",
    "\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
